1.	目录
1.	目录	1
1.	研究背景	2
2.	学位论文进展情况，存在的问题，已取得阶段性成果	2
2.1	可靠性基准测试研究现状	2
2.2	系统架构	3
2.3	构造典型应用	4
2.4异常数据生成器	5
2.4.1 数据生成脚本	6
2.5组合参数测试	7
2.6测试报告	7
2.7 实验验证	7
2.3 存在的问题	7
2.4 已取得的阶段性成果	7
3.	下一步工作计划和内容，预计答辩时间	7
3.1下一步工作计划	7
3.2 预计答辩时间	7
4.	参考文献	7

 
1.	研究背景
随着互联网、移动互联网和物联网的发展，越来越多的领域产生了“海量”和“高速”的数据[1]。这些数据具有数据规模大，产生速度快的特点，而且在这些数据中也隐藏着巨大的价值。因此，对这些海量数据的处理分析已经成为一个迫切的需求。例如在金融领域，其日常运营过程中会产生大量的数据，这些数据产生速度快，并且时效性短，通过对这些海量数据进行计算和分析，发现隐藏在其中的特征，可以帮助金融行业进行实时决策，从而更好的进行风险管理以及实现商业智能化[2]。又如在移动通信领域，一个大型城市中每分钟都会有超过8万条的位置更新数据，每天的网络承载流量高达100TB，如果可以对这些海量数据进行实时的挖掘分析，可以降低电话诈骗造成的损失[1]。
为了应对海量数据产生以及发现其背后隐藏的巨大价值，许多大数据处理系统应运而生，如Storm[3]、Hadoop[4]、Spark[5]、Flink[6]等。这些系统针对大数据处理给出了自己的解决方案，可以应对大数据所呈现的易失性、突发性、无序性等特点，但是仍然存在着许多关键性的问题，如系统本身是否可靠，即部署好或升级后的系统是否存在缺陷；又如系统提供的应用是否可靠，即开发好的系统应用是否存在潜在的运行时错误。现有的大数据平台的测试基准如HiBench[7]、BigSQL benchmark[8]以及Spark-perf[9]等，关注的焦点主要是在平台的性能及扩展性的基准测试上，对于大数据平台的可靠性测试目前还没有一套类似的测试基准提供支持。大数据平台在处理“海量”和“高速”数据时，是否可以高可靠的应对高负载的场景已经成为一个亟待解决的研究课题，本文将针对大数据平台的可靠性测试基准进行研究，并着重研究基准测试中的数据生成以及组合测试方法。
2.	 学位论文进展情况，存在的问题，已取得阶段性成果
总体上，学位论文进展良好，在理论研究和系统实现上都按照计划顺利进行。理论研究方面，已经完成了大数据平台可靠性框架的设计及数据生成和组合测试的初步研究；系统实现方面，已初步完成了该框架的原型工具的实现，能够对一些Spark应用进行可靠性的测试和分析。下面是详细的进展情况，包括可靠性框架的设计、数据生成和组合测试的初步研究、存在的问题和已取得的阶段性成果。
2.1	可靠性基准测试研究现状
已有的关于大数据系统的可靠性研究主要有以下几点：
（1）在MapReduce应用内存使用问题方面：由Xu [10] 等人通过研究123个真实Hadoop和Spark应用的内存溢出错误，发现了内存溢出错误的三大原因：框架暂存的数据量过大，数据流异常，及内存使用密集的用户代码。同时，也从42个包含修复信息的错误中总结出了常用的修复方法。
（2）大数据在线查询分析错误方面：Li [11] 等人研究了250个SCOPE job（运行在微软的Dryad框架之上）的故障错误，发现错误主要原因是未定义的列，错误的数据模式，不正确的行格式等等。他们也发现3个内存溢出错误，错误原因是在内存累积了大量的数据（比如一个大表的所有行被存放到内存中）。
（3）在大数据系统运行错误方面：Kavulya等人 [12] 分析了4100个执行失败的Hadoop jobs，这些jobs运行在Yahoo!管理的M45集群。他们发现36%的故障是数组访问越界错误，还有23%的故障是IO异常。
通过上述研究发现，大数据框架在运行时产生错误的原因主要有以下三点：
（1）数据异常：如数据维度过高、数据倾斜等；
（2）不恰当的参数配置：如系统分配内存的大小、reducer数目太小、决策树深度过大等；
（3）用户代码缺陷：如时间或是空间复杂度太高、有内存泄漏的风险等。
根据Li[11]等人的研究发现，大多数的故障（84.5%）是在数据处理过程中造成的而不是由代码中的逻辑缺陷引起的。因此，目前我们主要考虑由数据异常以及参数配置引起的异常情况。
2.2	系统架构
通过深入了解并分析与本课题相关的研究成果，我们希望提出一套可靠性测试基准，能够自动生成异常数据并组合参数进行测试，从而发现大数据框架可能会出现的运行时错误和系统缺陷。在研究可靠性测试基准的基础上，我们设计并实现了一套自动化的基准测试以下是我们设计的可靠性测试系统的框架流图，如图1所示，主要包括5个部分：配置待测系统、构造典型应用、异常数据生成器、组合参数测试、测试报告及分析。
 
图表 1 框架流图
1）	配置待测系统：用户提供待测系统（Spark或Flink集群）的Master节点的信息，用于接收基准测试系统发送的测试请求。
2）	构造典型应用：选取Spark或Flink中SQL、Machine Learning（ML）、Graph的有代表性的应用，提供Batch和Streaming两种处理方式的。
3）	异常数据生成器：基于真实数据，扩展生成异常数据；根据异常数据特征，如数据量大、数据分布倾斜、数据维度高、数据稀疏程度高等，组合参数生成异常数据。
4）	组合参数测试：根据选取的应用实例，人工的提供系统参数和应用参数进行组合测试；根据选取的应用实例以及设定的参数范围，自动化的进行参数组合测试。
5）	测试报告及分析：测试过程中，监控待测系统测试过程中的运行指标（内存、CPU等资源占有情况）；测试结束后，报告测试的配置信息、运行指标，同时报告错误信息（出错类型或未发现错误）以及可靠性分析。
接下来将对其中的主要模块：生成异常数据、组合参数测试以及测试报告进行详细说明。
2.3	构造典型应用
以Spark和Flink为例，SQL、Machine Learning以及Graph是大数据系统中经常使用的应用库。针对目前大数据框架提供的各类应用，本系统主要针对以下几种典型应用提供可靠性测试基准：
表格 1 典型应用
类别	应用	计算特点	输入数据
SQL	Scan	过滤	单个二维表

	Aggregate	聚合	
	Join	关联	多个二维表

	Mix	过滤、聚合、关联	
Machine
Learning	Logistics Regression	分类、迭代	多维数值型数据

	K-means	聚类、迭代	
	Decision Tree	分类、递归	多维数值型、离散型数据
	Random Forest	分类、递归	
Graph	PageRank	迭代	稠密图、稀疏图
	ConnectedComponents	迭代	
	Triangle Count	迭代	
在每个应用模块中，我们选取了其中有代表性的应用作为典型应用进行研究。这些应用有各自的计算特点，并且接收的输入数据类型不尽相同。应用本身的计算特点以及接收的数据类型都有可能导致不同的错误产生。举例来说，对于SQL模块中的Join操作，因为其计算特性要求接收的输入数据是多个二维表，若在计算过程中其只接收了单个二维表，这种输入数据的错误必定会造成应用错误。
我们将通过对现有的大数据框架中的几种典型应用的研究，同时分析应用的计算特性和输入数据特性，设计并实现针对大数据平台的可靠性测试基准。目前主要针对Spark和Flink平台提供可靠性测试基准。如图2、图3所示，Spark现阶段可以提供Spark SQL、Spark Streaming、MLlib、GraphX等应用方法库，Flink在Batch处理模式下提供GElly、FlinkML以及Table，在Streaming处理模式下支持Table应用。应用在不同的处理模式下可能会有不同的错误发生，因此，我们也会分别提供Batch以及Streaming两种处理模式的典型应用的可靠性测试基准。
     

2.4异常数据生成器
	我们把具有以下特点的数据称为异常数据：数据量大、数据倾斜、数据稀疏、数据维度高、数据分布异常。数据量大，即数据规模巨大，在当前应用配置下无法正常应对；数据倾斜，即；数据稀疏，；数据维度高，；数据分布异常，。
大数据平台在运行具体应用时，如果接收到异常数据，那么在其长时间运行时出现异常的可能性便会增加，本课题中，我们关注任务执行失败的情况。我们希望通过构造异常数据，来发现可能存在的潜在错误。可扩展的、高效的和接近实际的数据生成是数据密集型测试成功的关键。许多研究成果[14][15]正在解决扩展性的需求以及将实际工作特性反映到合成数据生成中。因此，我们需要设计并实现一种数据生成器进行异常数据的生成。
Agrawal[13]等人认为，数据生成器应该具备以下几点特征：1）接近实际的：尽管数据是合成的，但应该趋向真实，即可以代表真实数据集。真实的数据集一般具有属性相关性、代表高度倾斜的非均匀分布等特点。2）随机但可预测：数据应该足够随机来应对未知的数据集，但同时数据处理的输出必须是可以预测的。3）并行和分布式的：大规模数据的生成需要多核服务器并行工作来提高效率。4）可扩展的：允许用户从小规模单节点服务器扩展到多节点的大规模集群。
在上述基础之上，我们设计的数据生成器根据应用本身的性质，还包括以下几点特征：1）
通过研究数据生成器的特征，我们设计了一种异常数据生成器来针对选定的典型应用产生异常数据。异常数据生成器主要包括以下几个部分：数据生成脚本（包括原始数据格式化和随机数据合成两种方式）、数据生成集群（用于分布式产生数据的集群）。
 
图表 4 异常数据生成器
2.4.1 数据生成脚本
根据需要测试的SQL、Machine Learning（ML）以及Graph三个模块的应用，我们针对不同的模块分别提供了各自的数据生成脚本。
1）	SQL模块数据生成脚本
2）	ML模块数据生成脚本
[引用]现有的ML的数据集一般通过原始数据直接处理得到，即将大规模的数据集分割成若干份（如100G的原始数据，可以通过均分的方式分成10个10G的数据，从而进行扩展性测试）或是通过小规模数据集添加噪声（如有10G的原始数据，通过原始数据糅合高斯噪声形成新的10G的数据，此时这10G数据联合原始的10G数据便可形成20G的数据，且不是完全重复的）。
我们提供的数据生成脚本产生异常数据有两种途径：一是基于原始数据（即真实数据），扩展生成异常数据；二是根据异常数据的特征，随机合成的数据。(a) 对于基于原始数据的生成方式，首先进行预处理，即使用已有的真实的数据，将其转换成所需的格式，如剔除其中格式不正确或是修正其中格式错误的数据；其次提取需要的字段，即选取其中需要的字段组成新的数据集；最后需要进行格式归一化，即将各个维度的数据都归一化到同一区间。真实数据的各个属性分为标称属性（nominal attribute），二元属性（binary attribute），数值属性（numeric attribute）。标称属性的值是一些符号或事物的名称，每个值代表某种类别、编码或状态，可被看作是分类的；二元属性是一种特殊的标称属性，即只有0、1两种状态，通常0表示不出现，1表示出现；数值属性是定量的，即是可度量的量，它的值可以是区间标度的或比率标度的。因此，标称属性和二元属性都是离散的，数值属性可以是离散的或连续的。我们将标称属性转换成向量矩阵，二元属性用0和1表示，在有监督的学习中，选择其中一个二元属性作为标签，数值属性保留为原来的数值。(b)对于随机合成的数据，根据上述介绍的两种数据格式生成不同维度、实例数、稀疏度即分布形式的数据。其中，稀疏度分为整体的稀疏度和特征的稀疏度；分布形式分为标准正态分布、Gamma分布、泊松分布、指数分布、均匀分布和混合分布等。每个样例的同一个属性符合某种分布。混合分布是指混合了以上各种分布的属性集合。通过设定不同的数据特征信息，生成接近于真实数据的随机合成数据。
 
图表 5 ML数据生成脚本
3）	Graph模块数据生成脚本

2.5组合参数测试
2.6测试报告
2.7 实验验证
2.3 存在的问题
2.4 已取得的阶段性成果
3.	 下一步工作计划和内容，预计答辩时间
3.1下一步工作计划
1）	继续完善可靠性测试基准的理论研究，主要是数据生成方法和组合测试降维方法的研究。
2）	继续完善可靠性测试框架的工具实现，提供更加人性化的测试工具和更加详细的测试报告和分析。
3）	在测试框架基础上进行基准测试，完善实验数据及结果分析。
4）	撰写学位论文。
3.2 预计答辩时间
预计在2016年5月进行答辩。
4.	 参考文献
[1] 崔星灿, 禹晓辉, 刘洋,等. 分布式流处理技术综述[J]. 计算机研究与发展, 2015, 52(2):318-332.
[2] 孙大为, 张广艳, 郑纬民. 大数据流式计算:关键技术及系统实例[J]. 软件学报, 2014, 25(4):839-862.
[3] Storm
[4] Hadoop
[5] Spark
[6] Flink
[7] HiBench
[8] BigSQL benchmark
[9]Spark-perf
[10] Lijie Xu, Wensheng Dou, Feng Zhu, Chushu Gao, Jie Liu, Hua Zhong, Jun Wei. A Characteristic Study on Out of Memory Errors in Distributed Data-Parallel Applications. In the 26th IEEE International Symposium on Software Reliability Engineering (ISSRE 2015).
[11] S. Li, H. Zhou, H. Lin, T. Xiao, H. Lin, W. Lin, and T. Xie, “A characteristic study on failures of production distributed data-parallel programs,” in 35th International Conference on Software Engineering (ICSE), 2013, pp. 963–972.
[12] S. Kavulya, J. Tan, R. Gandhi, and P. Narasimhan, “Analysis of traces from a production mapreduce cluster,” in 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), 2010, pp. 94–103.
[13] Agrawal, Dakshi, et al. "SparkBench–A Spark Performance Testing Suite."Technology Conference on Performance Evaluation and Benchmarking. Springer International Publishing, 2015.
[14] Alexandrov, Alexander, Kostas Tzoumas, and Volker Markl. "Myriad: scalable and expressive data generation." Proceedings of the VLDB Endowment 5.12 (2012): 1890-1893.
[15] Rabl, Tilmann, et al. "A data generator for cloud-scale benchmarking."Technology Conference on Performance Evaluation and Benchmarking. Springer Berlin Heidelberg, 2010.
